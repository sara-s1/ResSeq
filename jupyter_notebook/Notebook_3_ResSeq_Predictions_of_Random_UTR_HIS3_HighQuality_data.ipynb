
"""
Created on Sat Sep 14 13:30:44 2019

@author: sara salah
"""

import pandas as pd
import numpy as np

################################################################
# download the data
#!wget https://github.com/sara-s1/ResSeq/raw/master/Data/Sorted_UTRs

#########################
max_length =50
number_of_sequence=489348
sequence_size=max_length*4+1
number_of_element=number_of_sequence*sequence_size
print ("number_of_element" ,number_of_element)

######################################################################################

def make_image(seq):
    image=np.zeros(shape=(4,max_length),dtype=np.float16)
                 
    for i in range(len(seq)):
        if seq[i]=='A':
            image[0,i]=1
        elif seq[i]=='T':
            image[1,i]=1
        elif seq[i]=='G':
             image[2,i]=1
        else:
            image[3,i]=1
                            
    return image

######################################################################################

def encode_feature(seq,lable):
    s=np.zeros(shape=(201,1),dtype=np.float16)
    x_image=make_image(seq) 
    s[0]=lable
    s[1:201]=x_image.reshape(4*max_length,1)
    return s

######################################################################################

def Generate_binary(seq_file,Flage):
    s=np.zeros(shape=(number_of_element,1),dtype=np.float16)
    data=pd.read_csv(seq_file)
    print (len(data))
    print("------")
    seq=data['UTR'].values
    label=data['growth_rate'].values
  
    start=0
    end=sequence_size
    for i in range(len(data)):   #(number_of_sequence):
        #e=encode_feature(data['UTR'].values[i],data['growth_rate'].values[i])
        s[start:end]=encode_feature(data['UTR'].values[i],data['growth_rate'].values[i]/4)
        start=start+sequence_size
        end=end+sequence_size
        if(i%10000==0):
            print(i)
    if Flage=="Train":
        s.tofile("s_Train.bin")
    else:
        s.tofile("s_Test.bin")
        
    
Generate_binary("Sorted_UTRs_Train.csv","Train") 
Generate_binary("Sorted_UTRs_Test.csv","Test")


import tensorflow as tf
import numpy as np
import os 

_HEIGHT = 4
_WIDTH = 50
_DEPTH = 1
NUM_CLASSES = 1
NUM_DATA_FILES = 1

# run eager execution
#tf.enable_eager_execution()


filepath='D:/deepLearning/5UTR/5UTR_me_divideData'
#filename='s.bin'

#file_data= [os.path.join(filepath, filename)]
def get_filenames(is_training, data_dir):
    if is_training==1:
        return [os.path.join(data_dir, 's_Train.bin')]
    else:
        return [os.path.join(data_dir, 's_Test.bin')]

def record_dataset(filenames):
  """Returns an input pipeline Dataset from `filenames`."""
  record_bytes = 402
  return tf.data.FixedLengthRecordDataset(filenames, record_bytes)

def parse_record(raw_record):
  """Parse CIFAR-10 image and label from a raw record."""
  # Every record consists of a label followed by the image, with a fixed number
  # of bytes for each.
  label_bytes = 2
  image_bytes = 2*(_HEIGHT * _WIDTH * _DEPTH)
  record_bytes = label_bytes + image_bytes

  # Convert bytes to a vector of uint8 that is record_bytes long.
  record_vector = tf.decode_raw(raw_record, tf.float16)

  # The first byte represents the label, which we convert from uint8 to int32
  # and then to one-hot.
  label = tf.cast(record_vector[0], tf.float32)
  #label = tf.one_hot(label, _NUM_CLASSES)

  # The remaining bytes after the label represent the image, which we reshape
  # from [depth * height * width] to [depth, height, width].
  depth_major = tf.reshape(
      record_vector[1:201], [_DEPTH, _HEIGHT, _WIDTH])

  # Convert from [depth, height, width] to [height, width, depth], and cast as
  # float32.
  image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)
  
  print('image.shape',image.shape)

  return image, label



def input_fn(is_training, data_dir, batch_size, num_epochs=1):
  """Input_fn using the tf.data input pipeline for CIFAR-10 dataset.

  Args:
    is_training: A boolean denoting whether the input is for training.
    data_dir: The directory containing the input data.
    batch_size: The number of samples per batch.
    num_epochs: The number of epochs to repeat the dataset.

  Returns:
    A tuple of images and labels.
  """
  dataset = record_dataset(get_filenames(is_training, data_dir))
 

  if is_training:
    # When choosing shuffle buffer sizes, larger sizes result in better
    # randomness, while smaller sizes have better performance. Because CIFAR-10
    # is a relatively small dataset, we choose to shuffle the full epoch.
    dataset = dataset.shuffle(buffer_size=10000)


  dataset = dataset.map(parse_record)
  
  dataset = dataset.prefetch(batch_size)

  # We call repeat after shuffling, rather than before, to prevent separate
  # epochs from blending together.
  dataset = dataset.repeat(num_epochs)

  # Batch results by up to batch_size, and then fetch the tuple from the
  # iterator.
  dataset = dataset.batch(batch_size)
  iterator = dataset.make_one_shot_iterator()
  images, labels = iterator.get_next()
  
  print ("images.shape",images.shape)
  print("labels",labels.shape)
  
  
  #return seqeunces and lables
  return images, labels



_BATCH_NORM_DECAY = 0.997
_BATCH_NORM_EPSILON = 1e-5

def batch_norm_relu(inputs, is_training, data_format):
  """Performs a batch normalization followed by a ReLU."""
  # We set fused=True for a significant performance boost. See
  # https://www.tensorflow.org/performance/performance_guide#common_fused_ops
  inputs = tf.layers.batch_normalization(
      inputs=inputs, axis=1 if data_format == 'channels_first' else 3,
      momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,
      scale=True, training=is_training, fused=True)
  inputs = tf.nn.relu(inputs)
  return inputs

def conv2d_fixed_padding(inputs, filters, kernel_size, strides, data_format):
  """Strided 2-D convolution with explicit padding."""
  # The padding is consistent and is based only on `kernel_size`, not on the
  # dimensions of `inputs` (as opposed to using `tf.layers.conv2d` alone).
  if strides > 1:
    inputs = fixed_padding(inputs, kernel_size, data_format)

  return tf.layers.conv2d(
      inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides,
      padding='SAME', use_bias=False,
      kernel_initializer=tf.variance_scaling_initializer(),activation='relu',
      data_format=data_format)

def building_block(inputs, filters, is_training, projection_shortcut, strides,
                   data_format):
  """Standard building block for residual networks with BN before convolutions.

  Args:
    inputs: A tensor of size [batch, channels, height_in, width_in] or
      [batch, height_in, width_in, channels] depending on data_format.
    filters: The number of filters for the convolutions.
    is_training: A Boolean for whether the model is in training or inference
      mode. Needed for batch normalization.
    projection_shortcut: The function to use for projection shortcuts (typically
      a 1x1 convolution when downsampling the input).
    strides: The block's stride. If greater than 1, this block will ultimately
      downsample the input.
    data_format: The input format ('channels_last' or 'channels_first').

  Returns:
    The output tensor of the block.
  """
  shortcut = inputs
  inputs = batch_norm_relu(inputs, is_training, data_format)

  # The projection shortcut should come after the first batch norm and ReLU
  # since it performs a 1x1 convolution.
  if projection_shortcut is not None:
    shortcut = projection_shortcut(inputs)

  inputs = conv2d_fixed_padding(
      inputs=inputs, filters=filters, kernel_size=4, strides=strides,
      data_format=data_format)

  inputs = batch_norm_relu(inputs, is_training, data_format)
  inputs = conv2d_fixed_padding(
      inputs=inputs, filters=filters, kernel_size=4, strides=1,
      data_format=data_format)

  return inputs + shortcut

def block_layer(inputs, filters, block_fn, blocks, strides, is_training, name,
                data_format):
  """Creates one layer of blocks for the ResNet model.

  Args:
    inputs: A tensor of size [batch, channels, height_in, width_in] or
      [batch, height_in, width_in, channels] depending on data_format.
    filters: The number of filters for the first convolution of the layer.
    block_fn: The block to use within the model, either `building_block` or
      `bottleneck_block`.
    blocks: The number of blocks contained in the layer.
    strides: The stride to use for the first convolution of the layer. If
      greater than 1, this layer will ultimately downsample the input.
    is_training: Either True or False, whether we are currently training the
      model. Needed for batch norm.
    name: A string name for the tensor output of the block layer.
    data_format: The input format ('channels_last' or 'channels_first').

  Returns:
    The output tensor of the block layer.
  """
  # Bottleneck blocks end with 4x the number of filters as they start with
  filters_out = 4 * filters if block_fn is bottleneck_block else filters

  def projection_shortcut(inputs):
    return conv2d_fixed_padding(
        inputs=inputs, filters=filters_out, kernel_size=1, strides=strides,
        data_format=data_format)

  # Only the first block per block_layer uses projection_shortcut and strides
  inputs = block_fn(inputs, filters, is_training, projection_shortcut, strides,
                    data_format)


  for _ in range(1, blocks):
    inputs = block_fn(inputs, filters, is_training, None, 1, data_format)

  return tf.identity(inputs, name)

def bottleneck_block(inputs, filters, is_training, projection_shortcut,
                     strides, data_format):
  """Bottleneck block variant for residual networks with BN before convolutions.

  Args:
    inputs: A tensor of size [batch, channels, height_in, width_in] or
      [batch, height_in, width_in, channels] depending on data_format.
    filters: The number of filters for the first two convolutions. Note that the
      third and final convolution will use 4 times as many filters.
    is_training: A Boolean for whether the model is in training or inference
      mode. Needed for batch normalization.
    projection_shortcut: The function to use for projection shortcuts (typically
      a 1x1 convolution when downsampling the input).
    strides: The block's stride. If greater than 1, this block will ultimately
      downsample the input.
    data_format: The input format ('channels_last' or 'channels_first').

  Returns:
    The output tensor of the block.
  """
  shortcut = inputs
  inputs = batch_norm_relu(inputs, is_training, data_format)

  # The projection shortcut should come after the first batch norm and ReLU
  # since it performs a 1x1 convolution.
  if projection_shortcut is not None:
    shortcut = projection_shortcut(inputs)

  inputs = conv2d_fixed_padding(
      inputs=inputs, filters=filters, kernel_size=1, strides=1,
      data_format=data_format)

  inputs = batch_norm_relu(inputs, is_training, data_format)
  inputs = conv2d_fixed_padding(
      inputs=inputs, filters=filters, kernel_size=3, strides=strides,
      data_format=data_format)

  inputs = batch_norm_relu(inputs, is_training, data_format)
  inputs = conv2d_fixed_padding(
      inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,
      data_format=data_format)

  return inputs + shortcut



def seqnet_resnet(features,labels,mode,params):

#    tf.disable_eager_execution()

    seq_data_format =  'channels_last'
    num_blocks = 1
    is_training=True
    
    inputs = features

    inputs = conv2d_fixed_padding(inputs=inputs, filters=16, kernel_size=4, strides=1,data_format=seq_data_format)
    inputs = tf.identity(inputs, 'initial_conv')

    inputs = block_layer(inputs=inputs, filters=32, block_fn=building_block, blocks=num_blocks,
             strides=1, is_training=is_training, name='block_layer1',
             data_format=seq_data_format)

    inputs = block_layer(inputs=inputs, filters=64, block_fn=building_block, blocks=num_blocks,
             strides=1, is_training=is_training, name='block_layer2',
             data_format=seq_data_format)

    inputs = block_layer(inputs=inputs, filters=128, block_fn=building_block, blocks=num_blocks,
             strides=1, is_training=is_training, name='block_layer3',
             data_format=seq_data_format)
    
    inputs = block_layer(inputs=inputs, filters=265, block_fn=building_block, blocks=num_blocks,
             strides=1, is_training=is_training, name='block_layer4',
             data_format=seq_data_format)
    
   

    inputs = batch_norm_relu(inputs, is_training,data_format=seq_data_format)

    inputs = tf.layers.average_pooling2d(
            inputs=inputs, pool_size=4, strides=1, padding='VALID',
            data_format=seq_data_format)
    inputs = tf.identity(inputs, 'final_avg_pool')
    print(inputs.shape)
    inputs = tf.reshape(inputs, [-1, 265*47])

    inputs = tf.layers.dense(inputs=inputs, units=16,activation='relu')
    inputs = tf.layers.dense(inputs=inputs, units=16,activation='relu')
    inputs = tf.layers.dense(inputs=inputs, units=1,activation='tanh')


    inputs = tf.identity(inputs, 'final_dense')
    
    predictions = tf.squeeze(inputs, 1)    
    labelT=tf.reshape(labels,[-1,1])
    labelT=labels

    print(labels)
    print(inputs)
    loss = tf.losses.absolute_difference(predictions=predictions, labels=labelT)
    print(loss)
    
    
    global_step = tf.train.get_or_create_global_step()
    _learning_rate = 0.001 
    _MOMENTUM = 0.9

    optimizer = tf.train.AdamOptimizer(learning_rate=_learning_rate)
    
    

    
    # Batch norm requires update_ops to be added as a train_op dependency.
    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    print(update_ops)

    with tf.control_dependencies(update_ops):
      train_op = optimizer.minimize(loss, global_step)
      
      
    # Calculate root mean squared error
    #print(labelT.shape, predictions.shape)
    accuracy = tf.contrib.metrics.streaming_pearson_correlation(predictions=predictions, labels=labelT)
    metrics = {'accuracy': accuracy}
    
    # Create a tensor named train_accuracy for logging purposes.
    tf.identity(accuracy[1], name='train_accuracy')
    tf.summary.scalar('train_accuracy', accuracy[1])
    
    
    print('hi\n')

    
    return tf.estimator.EstimatorSpec(
      mode=mode,
      # Report sum of error for compatibility with pre-made estimators
      loss=loss,
      train_op=train_op,

      eval_metric_ops=metrics)
    


 #########################
 # Using the Winograd non-fused algorithms provides a small performance boost.
import os
os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'

  # Set up a RunConfig to only save checkpoints once per training cycle.
run_config = tf.estimator.RunConfig().replace(save_checkpoints_secs=1e9)
  
# Set up a RunConfig to only save checkpoints once per training cycle.
#strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
#run_config = tf.estimator.RunConfig(train_distribute=strategy)
  
  
resnet_classifier = tf.estimator.Estimator(
      model_fn=seqnet_resnet, model_dir='D:/deepLearning/5UTR/5UTR_me_divideData', config=run_config,
      params={
          
          'resnet_size': 100,
          'data_format': 'first',
          'batch_size': 1000,
      })

  # Train the model.
for _ in range(1):
    tensors_to_log = {
        'train_accuracy': 'train_accuracy',
        
        
    }
logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)

print('Starting a training cycle.')

tf.logging.set_verbosity(tf.logging.INFO)

resnet_classifier.train(
    input_fn=lambda: input_fn(1,filepath,1024, num_epochs=2),hooks=[logging_hook],steps=10000)#steps=10000000
print("*********************ALLAH**********************")
ev=resnet_classifier.evaluate(
    input_fn=lambda: input_fn(0,filepath, 1000, num_epochs=2))
print(ev)

#def plot_history(history):
#  hist = pd.DataFrame(history.history)
#  hist['epoch'] = history.epoch
#
#  plt.figure()
#  plt.xlabel('Epoch')
#  plt.ylabel('Mean Abs Error [MPG]')
#  plt.plot(hist['epoch'], hist['mean_absolute_error'],
#           label='Train Error')
#  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],
#           label = 'Val Error')
#  plt.ylim([0,5])
#  plt.legend()
#
#  plt.figure()
#  plt.xlabel('Epoch')
#  plt.ylabel('Mean Square Error [$MPG^2$]')
#  plt.plot(hist['epoch'], hist['mean_squared_error'],
#           label='Train Error')
#  plt.plot(hist['epoch'], hist['val_mean_squared_error'],
#           label = 'Val Error')
#  plt.ylim([0,20])
#  plt.legend()
#  plt.show()
#
#
#plot_history(history)
#import matplotlib.pyplot as plt
#
#params={'resnet_size': 100, 'data_format': 'first','batch_size':100}
#
#(seq,label)=input_fn(1, filepath, 100, num_epochs=5)
#network = seqnet_resnet(seq,label,1,params)
#
#
#
##train_op = optimizer.minimize(loss=average_loss, global_step=tf.train.get_global_step())
#
#
#with tf.Session() as sess:
#  L1_output=sess.run(tf.global_variables_initializer())
#  
#global_step = tf.train.get_or_create_global_step()
#loss = tf.losses.absolute_difference(predictions=predictions, labels=labelT)
#optimizer =tf.train.AdamOptimizer(learning_rate=0.001)
#train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())
#update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
#with tf.control_dependencies(update_ops):
#  train_op = optimizer.minimize(loss, global_step)
#  
#print(train_op)
#plt.plot(n,Label,'ro', label='Original data')
#plt.legend()
#plt.show()
import datetime
log_dir="D:/deepLearning/5UTR/5UTR_me_on_smallData" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)
